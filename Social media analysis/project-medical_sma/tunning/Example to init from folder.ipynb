{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, BertForMaskedLM, BertTokenizer\n",
    "import torch\n",
    "PATH = f\"model/\"\n",
    "model = BertForMaskedLM.from_pretrained(PATH, local_files_only=True)\n",
    "token = AutoTokenizer.from_pretrained(PATH, local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = token(\"Piękny dzień na umieranie dupa dupa dupa\" ,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 768])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(x.input_ids,x.token_type_ids,x.attention_mask,output_hidden_states=True)\n",
    "out.hidden_states[-1].shape #ostatni z tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 768])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_last_state = out.hidden_states[-1]\n",
    "out_last_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer_hert = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "model_hert = AutoModel.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "x = tokenizer_hert(\"Piękny dzień na umieranie\" ,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2= model_hert(**x,output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(out2.hidden_states[12],out2.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-5fdd2bbbe15c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'BaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "out2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"Doctor_herbert.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.save_pretrained(\"Doctor_herbert_tokenizer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[46.0774, 12.4273, 90.8349,  ..., 96.3813, 86.7856, 93.8837],\n",
       "         [12.4587, -1.5829, 25.8648,  ..., 25.0138, 22.7272, 13.7484],\n",
       "         [31.2926,  5.6838, 63.3686,  ..., 73.9707, 52.8387, 62.9607],\n",
       "         ...,\n",
       "         [32.8941,  4.5027, 53.3479,  ..., 44.1747, 44.2345, 48.8496],\n",
       "         [25.6546,  4.3567, 46.2832,  ..., 41.8818, 39.8365, 48.0992],\n",
       "         [31.2739,  5.6526, 63.3658,  ..., 73.9312, 52.8506, 62.9046]]],\n",
       "       grad_fn=<AddBackward0>), hidden_states=(tensor([[[-0.0058,  0.4527,  0.2419,  ..., -0.0048,  0.4201,  0.1291],\n",
       "         [ 0.2933,  0.3968,  0.4653,  ..., -0.4542, -0.0319,  0.2603],\n",
       "         [-0.1938,  0.3774, -0.1191,  ..., -0.1214, -0.2571,  0.2426],\n",
       "         ...,\n",
       "         [-0.1047,  0.1537,  0.1553,  ...,  0.1825, -0.0399,  0.0604],\n",
       "         [ 0.2700,  0.0867,  0.1646,  ...,  0.0690, -0.1006, -0.1530],\n",
       "         [-0.0227,  0.2291,  0.0543,  ...,  0.0455,  0.0101,  0.0192]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.3608,  0.8314,  0.4389,  ..., -0.0161,  0.5007,  0.4593],\n",
       "         [ 0.3694,  0.7998,  0.5920,  ..., -0.6425,  0.2025,  0.3972],\n",
       "         [-0.2743,  0.4133, -0.4396,  ..., -0.3878, -0.1512,  0.5817],\n",
       "         ...,\n",
       "         [-0.0068,  0.2764,  0.2964,  ...,  0.8308, -0.0957,  0.5641],\n",
       "         [ 0.1998, -0.1654, -0.0260,  ...,  0.1825, -0.3334, -0.3800],\n",
       "         [-0.0628,  0.1087, -0.0688,  ...,  0.0972,  0.1467, -0.0956]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.4778,  0.7232, -0.0795,  ..., -0.1814,  0.5730,  0.2187],\n",
       "         [ 0.0803,  0.6206,  0.4038,  ..., -0.4514,  0.0320,  0.4682],\n",
       "         [-0.0202, -0.0261, -0.0134,  ..., -0.0285, -0.0388, -0.0092],\n",
       "         ...,\n",
       "         [ 0.0719,  0.5801,  0.3611,  ...,  0.6196, -0.3478,  0.3243],\n",
       "         [ 0.2133,  0.1104, -0.1070,  ...,  0.0023,  0.1787, -0.1627],\n",
       "         [ 0.3082,  0.0480, -0.2025,  ...,  0.2565,  0.0897, -0.2967]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.4278,  0.5324, -0.0463,  ..., -0.3914,  0.5418,  0.5292],\n",
       "         [ 0.1710,  0.4086,  0.3702,  ..., -0.5063,  0.2163,  0.5078],\n",
       "         [-0.0378, -0.0385, -0.0492,  ..., -0.0321, -0.0299, -0.0456],\n",
       "         ...,\n",
       "         [ 0.2180,  0.3531,  0.3715,  ...,  0.6990, -0.1955,  0.0516],\n",
       "         [-0.1956, -0.1020, -0.2020,  ..., -0.0941,  0.4201, -0.0105],\n",
       "         [-0.2093,  0.2198, -0.7305,  ...,  0.4501,  0.0716, -0.6032]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.5514,  0.5800,  0.4927,  ..., -0.4935, -0.0783,  0.2861],\n",
       "         [-0.1646,  0.3974,  0.1449,  ..., -0.7227,  0.2004,  0.6178],\n",
       "         [-0.0176, -0.0225, -0.0195,  ..., -0.0662, -0.0314, -0.0513],\n",
       "         ...,\n",
       "         [ 0.0641,  0.2137,  0.1376,  ...,  0.8453,  0.0628,  0.2069],\n",
       "         [-0.2967, -0.0287, -0.1003,  ..., -0.5519,  0.2895,  0.0239],\n",
       "         [-1.0300, -0.1000, -0.7890,  ...,  0.4233, -0.0934, -0.9511]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.5954,  0.3611, -0.0729,  ..., -0.4156, -0.1972,  0.2351],\n",
       "         [-0.1612,  0.5680,  0.1517,  ..., -0.4817,  0.7426,  0.7927],\n",
       "         [-0.0207, -0.0047, -0.0210,  ..., -0.0545, -0.0240, -0.0709],\n",
       "         ...,\n",
       "         [ 0.3410, -0.1761,  0.8209,  ...,  0.6765, -0.0940,  0.0830],\n",
       "         [ 0.3104, -0.1134,  0.8045,  ..., -0.6785, -0.1404, -0.0134],\n",
       "         [-0.3478, -0.0422, -0.0899,  ...,  0.0961, -0.0268, -0.2630]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.5097,  0.0204, -0.0547,  ..., -0.2642, -0.1144,  0.1566],\n",
       "         [ 0.1452,  0.3109,  0.0889,  ..., -0.6004,  0.5413,  0.8134],\n",
       "         [-0.0085,  0.0071,  0.0044,  ..., -0.0473, -0.0102, -0.0357],\n",
       "         ...,\n",
       "         [-0.2209, -0.2876,  0.9176,  ...,  0.5377, -0.1311, -0.0447],\n",
       "         [-0.2827, -0.2921,  0.7497,  ..., -0.5903, -0.0473, -0.0479],\n",
       "         [-0.1054, -0.0291,  0.0418,  ...,  0.0033, -0.0419, -0.1529]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-8.4669e-01,  4.7501e-02,  4.2174e-02,  ..., -2.2709e-01,\n",
       "          -2.5323e-01,  1.9101e-01],\n",
       "         [ 1.1084e-01, -3.5041e-02,  1.4757e-01,  ..., -7.1333e-01,\n",
       "           3.4636e-01,  6.7244e-01],\n",
       "         [-2.1938e-02, -1.6028e-03,  2.2102e-03,  ..., -3.5918e-02,\n",
       "          -7.7475e-03, -3.9430e-02],\n",
       "         ...,\n",
       "         [-3.0015e-01, -1.0386e-01,  3.2618e-01,  ...,  7.4480e-01,\n",
       "           1.1941e-01,  7.9873e-02],\n",
       "         [-5.3677e-01, -4.6664e-01,  3.9716e-01,  ..., -3.0284e-01,\n",
       "           1.3997e-01,  2.1060e-01],\n",
       "         [-4.2582e-02, -6.2642e-03, -4.1965e-02,  ..., -1.4008e-02,\n",
       "          -4.3661e-04, -1.0017e-01]]], grad_fn=<NativeLayerNormBackward>), tensor([[[-0.6441,  0.0014, -0.6647,  ..., -0.2365, -0.5818,  0.1564],\n",
       "         [ 0.2262, -0.2936, -0.0666,  ..., -0.7113,  0.4437,  0.5469],\n",
       "         [-0.0152, -0.0016,  0.0180,  ..., -0.0365, -0.0069, -0.0204],\n",
       "         ...,\n",
       "         [-0.4436,  0.0582,  0.0954,  ...,  0.5887,  0.1330,  0.4409],\n",
       "         [-0.3703, -0.2949,  0.0242,  ..., -0.2519, -0.1085,  0.2475],\n",
       "         [-0.1005, -0.0988, -0.0424,  ...,  0.0038, -0.1496, -0.0760]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.6819, -0.0401, -0.1925,  ..., -0.5031, -0.2883,  0.0376],\n",
       "         [-0.0215, -0.5501, -0.1010,  ..., -0.8826,  0.5250,  0.4218],\n",
       "         [-0.0327, -0.0158,  0.0083,  ..., -0.0452, -0.0210, -0.0673],\n",
       "         ...,\n",
       "         [-0.3440, -0.3115, -0.2222,  ...,  0.5747,  0.2517,  0.4888],\n",
       "         [-0.1202, -0.3307, -0.4846,  ..., -0.3728,  0.1529,  0.2847],\n",
       "         [-0.0201, -0.0116, -0.0119,  ..., -0.0269, -0.0104, -0.0518]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.7554, -0.1446,  0.3083,  ..., -0.3343, -0.3159, -0.1416],\n",
       "         [-0.0436, -0.2855,  0.1646,  ..., -0.6321,  0.6613,  0.4406],\n",
       "         [-0.0283, -0.0272,  0.0114,  ..., -0.0151, -0.0189, -0.0543],\n",
       "         ...,\n",
       "         [-0.3345,  0.1135,  0.2657,  ...,  0.5489,  0.1491,  0.4978],\n",
       "         [-0.0884, -0.0910,  0.1234,  ..., -0.4736, -0.0094,  0.1770],\n",
       "         [-0.0123, -0.0096, -0.0009,  ..., -0.0172, -0.0134, -0.0328]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.3816, -0.1467,  0.3445,  ..., -0.2618, -0.1655, -0.0672],\n",
       "         [-0.1891, -0.1735,  0.0671,  ..., -0.4475,  0.6252,  0.4574],\n",
       "         [-0.0269, -0.0100, -0.0034,  ..., -0.0363,  0.0129, -0.0400],\n",
       "         ...,\n",
       "         [-0.0214,  0.0887,  0.2217,  ...,  0.5197,  0.2349,  0.4330],\n",
       "         [ 0.0781, -0.1141,  0.0294,  ..., -0.3623,  0.0384,  0.0989],\n",
       "         [-0.0322, -0.0087,  0.0069,  ..., -0.0365,  0.0136, -0.0336]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.1608,  0.0118,  0.1751,  ..., -0.5250,  0.0063,  0.1412],\n",
       "         [-0.2988,  0.0296,  0.0356,  ..., -1.0013,  0.4282,  0.5347],\n",
       "         [-0.4533,  0.5068, -0.2031,  ..., -0.3126,  0.3352,  1.2297],\n",
       "         ...,\n",
       "         [-0.0065, -0.0828, -0.3236,  ...,  0.1753,  0.3968,  0.4652],\n",
       "         [-0.1257, -0.2668, -0.1095,  ..., -0.8251,  0.2950,  0.2199],\n",
       "         [-0.4488,  0.5129, -0.1941,  ..., -0.3217,  0.3327,  1.2348]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)), attentions=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-6f441e475d06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.tensor(out.hidden_states).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bert',\n",
       "              BertModel(\n",
       "                (embeddings): BertEmbeddings(\n",
       "                  (word_embeddings): Embedding(50000, 768, padding_idx=1)\n",
       "                  (position_embeddings): Embedding(514, 768)\n",
       "                  (token_type_embeddings): Embedding(2, 768)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (encoder): BertEncoder(\n",
       "                  (layer): ModuleList(\n",
       "                    (0): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (1): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (2): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (3): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (4): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (5): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (6): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (7): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (8): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (9): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (10): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (11): BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )),\n",
       "             ('cls',\n",
       "              BertOnlyMLMHead(\n",
       "                (predictions): BertLMPredictionHead(\n",
       "                  (transform): BertPredictionHeadTransform(\n",
       "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  )\n",
       "                  (decoder): Linear(in_features=768, out_features=50000, bias=True)\n",
       "                )\n",
       "              ))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
